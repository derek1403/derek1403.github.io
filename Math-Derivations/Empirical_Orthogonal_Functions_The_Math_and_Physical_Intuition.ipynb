{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4ab8cd4",
   "metadata": {},
   "source": [
    "# 經驗正交函數 (Empirical Orthogonal Functions, EOF) : The Math and Physical Intuition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6423f7ae",
   "metadata": {},
   "source": [
    "## EOF 的數學本質\n",
    "\n",
    "在所有正交線性座標系中，能用最少 $r$ 個座標捕捉最多能量(最多資訊)的那一組\n",
    "\n",
    "$$\\mathbf{X} = \\sum_{k=1}^{r} \\sqrt{\\lambda_k} \\mathbf{\\phi}_k \\mathbf{p}_k^T$$\n",
    "\n",
    "其中：\n",
    "\n",
    "* **$\\mathbf{X}$：資料矩陣（距平值 Anomaly）**\n",
    "  * 空間資料數量： $n$ 、時間資料數量： $m$ 。大小 $(n \\times m)$\n",
    "  * 對於每個空間已減去該空間在時間上的平均\n",
    "* **$\\mathbf{\\phi}_k$：EOF 空間模態（特徵向量）**\n",
    "  * 空間上的分佈型態\n",
    "  * 維度為 $n \\times 1$\n",
    "  * 通常假定為單位向量 ( $||\\mathbf{\\phi}_k|| = 1$)\n",
    "  * 無因次\n",
    "* **$\\mathbf{p}_k$：PC（標準化時間係數）**\n",
    "  * 對應 $\\text{EOF}_k$ 的時間序列係數\n",
    "  * 維度為 $m \\times 1$，轉置後為 $1 \\times m$\n",
    "  * 公式裡 $\\sqrt{\\lambda_k}$ 被獨立提出來了，所以這裡的 $\\mathbf{p}_k$ 是單位向量( $||\\mathbf{p}_k|| = 1$) \n",
    "  * 無因次\n",
    "* **$\\lambda_k$：特徵值（解釋變異量）**\n",
    "  * 每個方向承載的能量(變異度)\n",
    "  * 純量\n",
    "  * $\\lambda_1 \\ge \\lambda_2 \\ge \\cdots$\n",
    "  * 因次為 $\\mathbf{X}$ 的平方"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c9a774",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{matrix}\n",
    "\\text{第 1 個空間點的時間序列} \\rightarrow\\\\\n",
    "\\text{第 2 個空間點的時間序列} \\rightarrow\\\\\n",
    "\\vdots \\\\\n",
    "\\text{第 } n \\text{ 個空間點的時間序列} \\rightarrow\n",
    "\\end{matrix}\n",
    "\\underset{\\substack{\\begin{matrix}\n",
    "\\uparrow & \\uparrow & & \\uparrow \\\\\n",
    "t_1 & t_2 & \\cdots & t_m \\\\\n",
    "\\text{時刻} & \\text{時刻} & & \\text{時刻}\n",
    "\\end{matrix}}}{\n",
    "\\begin{bmatrix}\n",
    "x_{1,1} & x_{1,2} & \\cdots & x_{1,m} \\\\\n",
    "x_{2,1} & x_{2,2} & \\cdots & x_{2,m} \\\\\n",
    "\\vdots  & \\vdots  & \\ddots & \\vdots  \\\\\n",
    "x_{n,1} & x_{n,2} & \\cdots & x_{n,m}  \\\\\n",
    "\\end{bmatrix}}\n",
    "=\\sum_{k=1}^{r} \\sqrt{\\lambda_k} \n",
    "\\underbrace{\\begin{bmatrix} \\phi_{1,k} \\\\ \\vdots \\\\ \\phi_{n,k} \\end{bmatrix}}_{\\text{空間型態 } (n \\times 1)} \n",
    "\\underbrace{\\begin{bmatrix} p_{k,1} & \\cdots & p_{k,m} \\end{bmatrix}}_{\\text{時間係數 } (1 \\times m)}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea2995e",
   "metadata": {},
   "source": [
    "## 假設與已知 (Assumptions & Preliminaries)\n",
    "\n",
    "* **【假設 1】線性疊加假設** ： 假設複雜的氣候場可以表示為幾個空間型態的 **線性組合** \n",
    "  \n",
    "  * 只關心二階統計，不看偏態、峰態、非線性結構\n",
    "  * **限制** ：對於強烈非線性、或存在「氣候模態切換 (Regime-switching)」的系統，線性的 EOF 可能會 **失真** ，這時可能需要考慮 Nonlinear PCA 或 Autoencoder。\n",
    "\n",
    "* **【已知 1】模態正交性** 數學上使拆解出來的每一個模態**空間**彼此垂直、**時間**彼此垂直（Uncorrelated）\n",
    "  \n",
    "  * **Space** ：$\\text{EOF}_i \\perp \\text{EOF}_j$ (不同空間結構完全不同)\n",
    "  * **Time** ：$\\text{PC}_i \\perp \\text{PC}_j$ (不同時間變化完全獨立)\n",
    "  * **限制** ：這純粹是為了數學上求出唯一解的方便，資料沒有義務要遵守正交性，真實的物理過程（如兩個交互作用的天氣系統）常常是非正交的\n",
    "\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d3ea68",
   "metadata": {},
   "source": [
    "## 第一部分：EOF的**矩陣**形式\n",
    "\n",
    "我們先**定義**這三個大矩陣長什麼樣子：\n",
    "\n",
    "* $\\mathbf{\\Phi}$ (空間矩陣)：把 $\\phi_1, \\phi_2$ 像柱子(column)一樣排起來。\n",
    "\n",
    "  $$\\mathbf{\\Phi} = \\begin{bmatrix} | & | & & | \\\\ \\mathbf{\\phi}_1 & \\mathbf{\\phi}_2 & \\cdots & \\mathbf{\\phi}_r \\\\ | & | & & | \\end{bmatrix}_{(n \\times r)}$$\n",
    "\n",
    "  * 滿足 $\\mathbf{\\Phi}^T \\mathbf{\\Phi} = \\mathbf{I}_{(r \\times r)}$ 、 $\\mathbf{\\Phi} \\mathbf{\\Phi}^T = \\mathbf{I}_{(n \\times n)}$\n",
    "\n",
    "* $\\sqrt{\\mathbf{\\Lambda}}$ (特徵矩陣)：把 $\\sqrt{\\lambda}$ 放在對角線(diagonal)上。\n",
    "\n",
    "  $$\\sqrt{\\mathbf{\\Lambda}} = \\begin{bmatrix} \\sqrt{\\lambda_1} & 0 & \\cdots & 0\\\\ 0 & \\sqrt{\\lambda_2} &\\cdots & 0\\\\  \\vdots&\\vdots&\\ddots &\\vdots \\\\0&0&\\cdots&\\sqrt{\\lambda_r} \\end{bmatrix}$$\n",
    "\n",
    "  * $\\sqrt{\\mathbf{\\Lambda}}\\sqrt{\\mathbf{\\Lambda}} = \\mathbf{\\Lambda}$\n",
    "  * **數學詮釋：** $\\mathbf{\\phi}_i$ 解釋了**資料總變異數**中的 $\\frac{\\mathbf{\\lambda}_i}{\\sum_{k=1}^{r}\\mathbf{\\lambda}_k}$ 比例\n",
    "\n",
    "* $\\mathbf{P}^T$ (時間矩陣的轉置)：把 $\\mathbf{p}_1^T, \\mathbf{p}_2^T$ 像橫梁(row)一樣疊起來。\n",
    "\n",
    "  $$\\mathbf{P}^T = \\begin{bmatrix} - \\mathbf{p}_1^T - \\\\ - \\mathbf{p}_2^T - \\\\ \\vdots \\\\ - \\mathbf{p}_r^T - \\end{bmatrix}$$\n",
    "\n",
    "  *  $\\mathbf{P}^T \\mathbf{P} = \\mathbf{I}_{(r \\times r)}$ 、 $\\mathbf{P} \\mathbf{P}^T = \\mathbf{I}_{(m \\times m)} $ \n",
    "  *  $\\mathbf{P} = \\begin{bmatrix} | & |& & | \\\\ \\mathbf{p}_1 & \\mathbf{p}_2 & \\cdots &\\mathbf{p}_r \\\\ | & |& & | \\end{bmatrix}_{(m \\times r)}$\n",
    "\n",
    "\n",
    "從 $\\mathbf{X} = \\sum_{k=1}^{r} \\sqrt{\\lambda_k} \\mathbf{\\phi}_k \\mathbf{p}_k^T$ 出發，寫成矩陣有利於後續的分解和化簡：\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "\\begin{bmatrix}\n",
    "x_{1,1} & x_{1,2} & \\cdots & x_{1,m} \\\\\n",
    "x_{2,1} & x_{2,2} & \\cdots & x_{2,m} \\\\\n",
    "\\vdots  & \\vdots  & \\ddots & \\vdots  \\\\\n",
    "x_{n,1} & x_{n,2} & \\cdots & x_{n,m}  \\\\\n",
    "\\end{bmatrix}\n",
    "&=&\\sum_{k=1}^{r} \\sqrt{\\lambda_k} \n",
    "\\begin{bmatrix} \\phi_{1,k} \\\\ \\vdots \\\\ \\phi_{n,k} \\end{bmatrix}\n",
    "\\begin{bmatrix} p_{k,1} & \\cdots & p_{k,m} \\end{bmatrix} \\\\\n",
    "&=&\n",
    "\\begin{bmatrix}\n",
    "\\sum_{k=1}^{r} \\sqrt{\\lambda_k} \\phi_{1,k}p_{k,1} & \\sum_{k=1}^{r} \\sqrt{\\lambda_k} \\phi_{1,k}p_{k,2} & \\cdots & \\sum_{k=1}^{r} \\sqrt{\\lambda_k} \\phi_{1,k}p_{k,m} \\\\\n",
    "\\sum_{k=1}^{r} \\sqrt{\\lambda_k} \\phi_{2,k}p_{k,1} & \\sum_{k=1}^{r} \\sqrt{\\lambda_k} \\phi_{2,k}p_{k,2} & \\cdots & \\sum_{k=1}^{r} \\sqrt{\\lambda_k} \\phi_{2,k}p_{k,m} \\\\\n",
    "\\vdots  & \\vdots  & \\ddots & \\vdots  \\\\\n",
    "\\sum_{k=1}^{r} \\sqrt{\\lambda_k} \\phi_{n,k}p_{k,1} & \\sum_{k=1}^{r} \\sqrt{\\lambda_k} \\phi_{n,k}p_{n,2} & \\cdots & \\sum_{k=1}^{r} \\sqrt{\\lambda_k} \\phi_{n,k}p_{k,m}  \\\\\n",
    "\\end{bmatrix}\\\\\n",
    "&=&\n",
    "\\begin{bmatrix}\n",
    "\\phi_{1,1} & \\phi_{1,2} & \\cdots & \\phi_{1,r} \\\\\n",
    "\\phi_{2,1} & \\phi_{2,2} & \\cdots & \\phi_{2,r} \\\\\n",
    "\\vdots  & \\vdots  & \\ddots & \\vdots  \\\\\n",
    "\\phi_{n,1} & \\phi_{n,2} & \\cdots & \\phi_{n,r}  \\\\\n",
    "\\end{bmatrix}_{(n \\times r)}\n",
    "\\begin{bmatrix}\n",
    "\\sqrt{\\lambda_1} & 0 & \\cdots & 0 \\\\\n",
    "0 & \\sqrt{\\lambda_2} & \\cdots & 0 \\\\\n",
    "\\vdots  & \\vdots  & \\ddots & \\vdots  \\\\\n",
    "0 & 0 & \\cdots & \\sqrt{\\lambda_r}  \\\\\n",
    "\\end{bmatrix}_{(r \\times r)}\n",
    "\\begin{bmatrix}\n",
    "p_{1,1} & p_{1,2} & \\cdots & p_{1,m} \\\\\n",
    "p_{2,1} & p_{2,2} & \\cdots & p_{2,m} \\\\\n",
    "\\vdots  & \\vdots  & \\ddots & \\vdots  \\\\\n",
    "p_{r,1} & p_{r,2} & \\cdots & p_{r,m}  \\\\\n",
    "\\end{bmatrix}_{(r \\times m)} \\\\\n",
    "&=&\n",
    "\\begin{bmatrix} | & | & & | \\\\ \\mathbf{\\phi}_1 & \\mathbf{\\phi}_2 & \\cdots & \\mathbf{\\phi}_r \\\\ | & | & & | \\end{bmatrix}\n",
    "\\begin{bmatrix} \\sqrt{\\lambda_1} & 0 & \\cdots & 0\\\\ 0 & \\sqrt{\\lambda_2} &\\cdots & 0\\\\  \\vdots&\\vdots&\\ddots &\\vdots \\\\0&0&\\cdots&\\sqrt{\\lambda_r} \\end{bmatrix}\n",
    "\\begin{bmatrix} - \\mathbf{p}_1^T - \\\\ - \\mathbf{p}_2^T - \\\\ \\vdots \\\\ - \\mathbf{p}_r^T - \\end{bmatrix} \\\\\n",
    "&\\overset{\\text{def}}{=}&\n",
    "\\mathbf{\\Phi} \\sqrt{\\mathbf{\\Lambda}}\\mathbf{P}^T\n",
    "\\end{matrix} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4627bda6",
   "metadata": {},
   "source": [
    "## 第二部分：推導 **共變異數矩陣($\\mathbf{C}$)** 並解**特徵值問題**\n",
    "\n",
    "我們先**定義**共變異數矩陣($\\mathbf{C}$)長什麼樣子：\n",
    "\n",
    "* $\\mathbf{C}_{(n \\times n)}$ (空間共變異數矩陣)\n",
    "  \n",
    "  * $\\mathbf{C}_{(n \\times n)} \\overset{\\text{def}}{=}\\frac{1}{m-1} \\mathbf{X}\\mathbf{X}^T $\n",
    "  * $\\mathbf{C}_{(n \\times n)} = \\mathbf{C}_{(n \\times n)}^T $\n",
    "  * $\\mathbf{C}_{(n \\times n)}$ 的第 $(i, j)$ 個元素告訴你：第 $i$ 個空間點和第 $j$ 個空間點的變化有多同步\n",
    "  * 特徵向量：直接得到 **空間模態 (Spatial Map, EOFs)**\n",
    "  * 解出 $\\mathbf{C}_{(n \\times n)}$ 的特徵向量矩陣 $\\mathbf{\\Phi}$（也就是 EOFs 空間地圖）後可以透過投影的方式找 PCs：$\\mathbf{p}_k^T = \\frac{1}{\\sqrt{\\lambda_k}} \\mathbf{\\phi}_k^T \\mathbf{X}$\n",
    "  \n",
    "* $\\mathbf{C}_{(m \\times m)}$ (時間共變異數矩陣)，或者$\\mathbf{C'}_{(m \\times m)}$\n",
    "  \n",
    "  * $\\mathbf{C}_{(m \\times m)} \\overset{\\text{def}}{=}\\frac{1}{n-1} \\mathbf{X}^T\\mathbf{X} $\n",
    "  * $\\mathbf{C}_{(m \\times m)} = \\mathbf{C}_{(m \\times m)}^T $\n",
    "  * $\\mathbf{C}_{(m \\times m)}$ 的第 $(i, j)$ 個元素告訴你：第 $i$ 個時間點和第 $j$ 個時間點的長得像不像\n",
    "  * 特徵向量：直接得到 **時間係數 (Time Series, PCs)**\n",
    "  * 解出 $\\mathbf{C}_{(m \\times m)}$ 的特徵向量矩陣 $\\mathbf{P}$（也就是 PCs 時間序列）後可以透過投影的方式找 EOFs：$\\mathbf{\\phi}_k = \\frac{1}{\\sqrt{\\lambda_k}} \\mathbf{X}  \\mathbf{p}_k  $\n",
    "\n",
    "化簡**空間共變異數矩陣**\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "\\mathbf{X}\\mathbf{X}^T &=& (\\mathbf{\\Phi} \\sqrt{\\mathbf{\\Lambda}} \\mathbf{P}^T) (\\mathbf{\\Phi} \\sqrt{\\mathbf{\\Lambda}} \\mathbf{P}^T)^T \\\\\n",
    "&=& \\mathbf{\\Phi} \\sqrt{\\mathbf{\\Lambda}} \\mathbf{P}^T \\mathbf{P} \\sqrt{\\mathbf{\\Lambda}}^T \\mathbf{\\Phi}^T \\\\\n",
    "&=& \\mathbf{\\Phi} \\sqrt{\\mathbf{\\Lambda}}  \\mathbf{I}  \\sqrt{\\mathbf{\\Lambda}} \\mathbf{\\Phi}^T \\\\\n",
    "&=& \\mathbf{\\Phi} \\mathbf{\\Lambda} \\mathbf{\\Phi}^T \\\\\n",
    "\\end{matrix} \n",
    "$$\n",
    "\n",
    "寫成**特徵值問題**的形式，因為**空間共變異數矩陣**的定義會需要乘一項 $\\frac{1}{m-1}$ 使原本的 $\\mathbf{\\Lambda}$ 需要調整成 $\\mathbf{\\Lambda}_{\\text{stat}}$ ，其中 $\\mathbf{\\Lambda}_{\\text{stat}} \\overset{\\text{let}}{=} \\frac{1}{m-1} \\mathbf{\\Lambda}$\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "(\\mathbf{X}\\mathbf{X}^T) \\mathbf{\\Phi} &=& \\mathbf{\\Phi} \\mathbf{\\Lambda}\\mathbf{\\Phi}^T \\mathbf{\\Phi}\\\\\n",
    "&=& \\mathbf{\\Phi} \\mathbf{\\Lambda}\\mathbf{I}\\\\\n",
    "\\mathbf{C}\\mathbf{\\Phi}&\\overset{\\text{def}}{=}& \\mathbf{\\Phi} \\mathbf{\\Lambda}_\\text{stat}\\\\\n",
    "\\frac{1}{m-1}\n",
    "\\begin{bmatrix}\n",
    "\\sum_{k=1}^{m} x_{1,k} x_{1,k} & \\sum_{k=1}^{m} x_{1,k} x_{2,k} & \\cdots & \\sum_{k=1}^{m} x_{1,k} x_{n,k} \\\\\n",
    "\\sum_{k=1}^{m} x_{2,k} x_{1,k} & \\sum_{k=1}^{m} x_{2,k} x_{2,k} & \\cdots & \\sum_{k=1}^{m} x_{2,k} x_{n,k} \\\\\n",
    "\\vdots  & \\vdots  & \\ddots & \\vdots  \\\\\n",
    "\\sum_{k=1}^{m} x_{n,k} x_{1,k} & \\sum_{k=1}^{m} x_{n,k} x_{2,k} & \\cdots & \\sum_{k=1}^{m} x_{n,k} x_{n,k}\n",
    "\\end{bmatrix}\n",
    "\\underset{\\text{單位特徵向量}}{\\begin{bmatrix} | & | & & | \\\\ \\mathbf{\\phi}_1 & \\mathbf{\\phi}_2 & \\cdots & \\mathbf{\\phi}_r \\\\ | & | & & | \\end{bmatrix}}\n",
    "&=& \\begin{bmatrix} | & | & & | \\\\ \\mathbf{\\phi}_1 & \\mathbf{\\phi}_2 & \\cdots & \\mathbf{\\phi}_r \\\\ | & | & & | \\end{bmatrix}\\frac{1}{m-1}\n",
    "\\begin{bmatrix} \\lambda_1 & 0 & \\cdots & 0\\\\ 0 & \\lambda_2 &\\cdots & 0\\\\  \\vdots&\\vdots&\\ddots &\\vdots \\\\0&0&\\cdots&\\lambda_r \\end{bmatrix}\\\\\n",
    "\\end{matrix} \n",
    "$$\n",
    "\n",
    "\n",
    "**數學詮釋：$\\mathbf{\\phi}_i$ 解釋了** 資料 $\\frac{\\mathbf{\\lambda}_i}{\\sum_{k=1}^{r}\\mathbf{\\lambda}_k}$ 的變異度\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f2bcd7",
   "metadata": {},
   "source": [
    "12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9090e76",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
